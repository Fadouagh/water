{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation in Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_path = open(\"files/twData_clean.csv\",\"r\")\n",
    "tw_data = pd.read_csv(tw_path, header=0, encoding = 'unicode_escape')\n",
    "tweets = tw_data.TwContent.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CountVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vec(text):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vocabulary=vectorizer.fit(text)\n",
    "    doc_term_matrix= vectorizer.transform(text)\n",
    "    final=doc_term_matrix.toarray()\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "        1]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec([tweets[212]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Making water corporus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('perturbations', 'perturbation'), ('coupures', 'coupure'), (' ', ' '), ('approvisionnement', 'approvisionnemer'), ('eau', 'eau'), ('potable', 'potable'), ('quelques', 'quelque'), ('régions', 'région'), ('jendouba', 'jendouba'), ('béja', 'béjer')]\n",
      "[(0, '0.028*\"eau\" + 0.025*\"les\"'), (1, '0.026*\"eau\" + 0.017*\"rt\"')]\n",
      "tweet 1:  les gouvernorats siliana kasserine jendouba souffrent coupures  eau potable\n",
      "tweet 2:  perturbations coupures  approvisionnement eau potable les gouvernorats siliana kasserine jendouba\n",
      "tweet 1:  les gouvernorats siliana kasserine jendouba souffrent coupures  eau potable\n",
      "tweet 2:  vol équipements sonede prive plusieurs régions  eau potable\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.Water_nlp import clean_collection\n",
    "import os\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdir = 'corpus/'\n",
    "#if not os.path.isdir(corpusdir):\n",
    "#    os.mkdir(corpusdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one file\n",
    "#def make_data_from_tweets(tweets):\n",
    "#    filename = 0\n",
    "#    file = open(corpusdir+'data.txt','a')\n",
    "#    for tw in tweets:\n",
    "#        file.write(tw)\n",
    "#        file.write('\\n')\n",
    "#    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate files\n",
    "#def make_text(data):\n",
    "#    filename = 0\n",
    "#    for text in data:\n",
    "#        print(text)\n",
    "#        filename+=1\n",
    "#        file = open(corpusdir+str(filename)+'.txt','w')\n",
    "#        file.write(text)#,encoding=\"UTF-8\")\n",
    "#        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_collection(tweets, lem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcorpus = PlaintextCorpusReader(corpusdir, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sonede', 'annonce', 'coupures', 'perturbations', ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cccess the plaintext; outputs pure string/basestring.\n",
    "#newcorpus.raw().strip()\n",
    "\n",
    "# Access paragraphs in the corpus. (list of list of list of strings)\n",
    "# NOTE: NLTK automatically calls nltk.tokenize.sent_tokenize and \n",
    "#       nltk.tokenize.word_tokenize.\n",
    "#\n",
    "# Each element in the outermost list is a paragraph, and\n",
    "# Each paragraph contains sentence(s), and\n",
    "# Each sentence contains token(s)\n",
    "#newcorpus.paras()\n",
    "#newcorpus.paras(newcorpus.fileids()[43])\n",
    "\n",
    "# Access sentences in the corpus. (list of list of strings)\n",
    "# NOTE: That the texts are flattened into sentences that contains tokens.\n",
    "#newcorpus.sents()\n",
    "#newcorpus.sents(newcorpus.fileids()[103])\n",
    "\n",
    "# Access just tokens/words in the corpus. (list of strings)\n",
    "#newcorpus.words()\n",
    "newcorpus.words(newcorpus.fileids()[436])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Word2Vec via gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['les', 'gouvernorats', 'siliana', 'kasserine', 'jendouba', 'souffrent', 'coupures', 'eau', 'potable'], ['jendouba', 'nord', 'vol', 'équipements', 'sonede', 'prive', 'plusieurs', 'régions', 'leau', 'potable'], ...]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newcorpus.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(newcorpus.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['les',\n",
       " 'jendouba',\n",
       " 'coupures',\n",
       " 'eau',\n",
       " 'potable',\n",
       " 'nord',\n",
       " 'vol',\n",
       " 'équipements',\n",
       " 'sonede',\n",
       " 'plusieurs',\n",
       " 'régions',\n",
       " 'leau',\n",
       " 'travaux',\n",
       " 'rt',\n",
       " 'électricité',\n",
       " 'a',\n",
       " 'bangui',\n",
       " 'odilon236',\n",
       " 'centrafrique',\n",
       " 'gouvernement',\n",
       " 'fait',\n",
       " 'peu',\n",
       " 'périphéries',\n",
       " 'faut',\n",
       " 'aussi',\n",
       " 'tunisie',\n",
       " 'prix',\n",
       " 'enfants',\n",
       " 'coupe',\n",
       " 'pendant',\n",
       " 'vie',\n",
       " 'accès',\n",
       " 'assainissement',\n",
       " 'millions',\n",
       " 'personnes',\n",
       " 'sans',\n",
       " 'dun',\n",
       " 'dune',\n",
       " 'mer',\n",
       " 'avant',\n",
       " 'deau',\n",
       " 'chaque',\n",
       " 'travers',\n",
       " 'milliards',\n",
       " 'cette',\n",
       " 'droit',\n",
       " 'reprise',\n",
       " 'approvisionnement',\n",
       " 'région',\n",
       " 'toujours',\n",
       " 'après',\n",
       " 'via',\n",
       " 'rouge',\n",
       " 'selon',\n",
       " 'peau',\n",
       " 'plus',\n",
       " 'besoin',\n",
       " 'dhydratation',\n",
       " 'peaux',\n",
       " 'mature',\n",
       " 'délicates',\n",
       " 'sensibles',\n",
       " 'fragiles',\n",
       " 'voici',\n",
       " 'bonheur',\n",
       " 'rééquilibrante',\n",
       " 'calmante',\n",
       " 'adoucissante',\n",
       " 'apaisante',\n",
       " 'disponible',\n",
       " 'immédiatement',\n",
       " 'heures',\n",
       " 'intestin',\n",
       " 'ni',\n",
       " 'beaucoup',\n",
       " 'jamais',\n",
       " 'rien',\n",
       " 'cest',\n",
       " 'ça',\n",
       " 'sait',\n",
       " 'reconnu',\n",
       " 'ils',\n",
       " 'nont',\n",
       " 'acaweadvocate',\n",
       " 'reportage',\n",
       " 'mort',\n",
       " '4',\n",
       " 'recherche',\n",
       " 'wolordé',\n",
       " 'lextrême',\n",
       " 'cameroun',\n",
       " 'mesure',\n",
       " 'con',\n",
       " 'bouteille',\n",
       " 'sous',\n",
       " 'depuis',\n",
       " 'habitants',\n",
       " 'grenouille',\n",
       " 'là',\n",
       " 'faire',\n",
       " 'pénurie',\n",
       " 'eaux',\n",
       " 'parfum',\n",
       " 'pied',\n",
       " 'bien',\n",
       " 'si',\n",
       " 'deux',\n",
       " 'litres',\n",
       " 'ariana',\n",
       " 'distribution',\n",
       " 'demain',\n",
       " 'partir',\n",
       " '21h',\n",
       " 'gens',\n",
       " 'boire',\n",
       " 'près',\n",
       " 'el',\n",
       " 'plage',\n",
       " 'propose',\n",
       " 'compose',\n",
       " 'grand',\n",
       " 'salon',\n",
       " 'magnésium',\n",
       " 'toutes',\n",
       " 'où',\n",
       " 'population',\n",
       " 'terrain',\n",
       " 'homme',\n",
       " 'comment',\n",
       " 'korba',\n",
       " 'quelques',\n",
       " '2',\n",
       " 'perturbation',\n",
       " 'lapprovisionnement',\n",
       " 'zones',\n",
       " 'raoued',\n",
       " 'minérale',\n",
       " 'unités',\n",
       " 'tout',\n",
       " 'peut',\n",
       " 'dire',\n",
       " 'comme',\n",
       " 'selim',\n",
       " 'region',\n",
       " 'monastir',\n",
       " 'ftdes',\n",
       " 'dénombre',\n",
       " '63',\n",
       " 'délavage',\n",
       " '55',\n",
       " 'délaver',\n",
       " 'jeans',\n",
       " '70',\n",
       " 'coupure',\n",
       " 'mardi',\n",
       " '19',\n",
       " '2019',\n",
       " 'tunis',\n",
       " 'jour',\n",
       " 'vais',\n",
       " 'quand',\n",
       " 'perturbations',\n",
       " 'gafsa',\n",
       " '28',\n",
       " 'opendata',\n",
       " 'passer',\n",
       " 'logiciellibre',\n",
       " 'commun',\n",
       " 'robinet',\n",
       " 'face',\n",
       " 'met',\n",
       " 'lait',\n",
       " 'personne',\n",
       " 'chez',\n",
       " 'vidéo',\n",
       " 'projets',\n",
       " 'sfax',\n",
       " 'projet',\n",
       " '24',\n",
       " '2010',\n",
       " '35',\n",
       " 'photos',\n",
       " 'webdotn',\n",
       " 'village',\n",
       " 'manque',\n",
       " 'tous',\n",
       " 'doit',\n",
       " 'fatymdiallo',\n",
       " 'hypotension',\n",
       " 'orthostatique',\n",
       " 'cause',\n",
       " 'fréquente',\n",
       " 'jeunes',\n",
       " 'déshydratation',\n",
       " 'mayahach',\n",
       " 'sidi',\n",
       " 'mansour',\n",
       " 'tourne',\n",
       " 'canal',\n",
       " 'production',\n",
       " 'traitement',\n",
       " 'route',\n",
       " 'usine',\n",
       " 'conduites',\n",
       " 'jelma',\n",
       " 'sauvagement',\n",
       " 'sabotées',\n",
       " 'réparées',\n",
       " 'leaderstunisie',\n",
       " 'tunivisions',\n",
       " 'hajerbj',\n",
       " 'domicile',\n",
       " 'devient',\n",
       " 'problème',\n",
       " 'épineux',\n",
       " 'matin',\n",
       " 'annonce',\n",
       " 'amina',\n",
       " 'sœur',\n",
       " 'compte',\n",
       " 'marques',\n",
       " 'minérales',\n",
       " 'jannet',\n",
       " 'safia',\n",
       " 'marwa',\n",
       " 'ain',\n",
       " 'oktor',\n",
       " 'garci',\n",
       " 'sabrine',\n",
       " 'fourat']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= list(model.wv.vocab)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02063291, -0.01813338,  0.01086354,  0.0134434 ,  0.00915405,\n",
       "        0.02108891,  0.01065617,  0.02074577,  0.00769985,  0.01990254,\n",
       "       -0.02011178,  0.04297063,  0.02321118, -0.0059525 ,  0.03947753,\n",
       "       -0.04503277, -0.01144692,  0.01881642,  0.04530437,  0.02835352,\n",
       "       -0.00862471,  0.0201069 , -0.02188269, -0.00801855,  0.0052058 ,\n",
       "        0.01359207, -0.03276923,  0.01789154,  0.01008898,  0.00985568,\n",
       "       -0.03815207, -0.01423651, -0.00664299, -0.01027305,  0.01282784,\n",
       "        0.0180391 , -0.01353645, -0.01564674, -0.00648039,  0.01461278,\n",
       "       -0.01277952,  0.01446649,  0.00389796, -0.02902619, -0.02264229,\n",
       "       -0.00277547, -0.00214725, -0.00998191,  0.02131425,  0.0018667 ,\n",
       "       -0.01637993,  0.00223922,  0.0351385 , -0.01511417,  0.04726404,\n",
       "        0.02909623, -0.00537001,  0.03337039,  0.00855758,  0.01612389,\n",
       "       -0.01463716, -0.02014721, -0.02466839,  0.02300984, -0.00235936,\n",
       "       -0.00975088,  0.01553993, -0.01757431,  0.02296903,  0.00388409,\n",
       "       -0.00118573, -0.02092747,  0.00363066,  0.00147803,  0.02551282,\n",
       "        0.00526109,  0.01918047,  0.01032388,  0.0057026 , -0.0350876 ,\n",
       "       -0.01120556, -0.01291638,  0.01907999,  0.02901671, -0.0242222 ,\n",
       "        0.00805479, -0.00704158,  0.01371202,  0.00664371,  0.02170463,\n",
       "        0.01865588, -0.00239958,  0.01486004, -0.00168855,  0.02983926,\n",
       "        0.01909002,  0.01160047,  0.00482916,  0.00712005, -0.00185546],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.wv['eau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('les', 0.9797747135162354),\n",
       " ('potable', 0.97902512550354),\n",
       " ('plus', 0.976499617099762),\n",
       " ('faut', 0.96953284740448),\n",
       " ('leau', 0.9686856269836426),\n",
       " ('sensibles', 0.9647523164749146),\n",
       " ('deau', 0.9641631245613098),\n",
       " ('a', 0.9630036354064941),\n",
       " ('fragiles', 0.9612061977386475),\n",
       " ('devient', 0.9610947370529175)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=model.most_similar('eau')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coupure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:876: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "dissimlar_words = model.wv.doesnt_match('coupure eau potable'.split())\n",
    "print(dissimlar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_two_words(model,w1, w2):\n",
    "    sim = model.wv.similarity(w1,w2)\n",
    "    #print(\"The similarity between <{}> and <{}>: \".format(w1, w2), sim)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9790251"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_two_words(model, 'eau', 'potable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8811195"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_two_words(model, 'eau', 'coupure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80485207"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_two_words(model, 'eau', 'jendouba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044895"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_two_words(model, 'eau', 'tunis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = gensim.models.Word2Vec(newcorpus.sents(),window=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.4739236e-03, -5.0116261e-03,  5.6540160e-03,  1.8106102e-03,\n",
       "        5.6086122e-03,  7.3115928e-03,  1.7290688e-03,  6.6596568e-03,\n",
       "        1.1793569e-03,  1.1043334e-02, -4.0303310e-03,  1.8670447e-02,\n",
       "        7.7683423e-03,  1.3546438e-03,  1.7171117e-02, -1.9719800e-02,\n",
       "       -6.4198407e-03,  9.2797028e-03,  1.6096259e-02,  8.3550084e-03,\n",
       "       -4.7245501e-03,  4.2333733e-03, -9.2747156e-03, -2.6546393e-03,\n",
       "        4.7225147e-03,  8.1469510e-03, -1.4849348e-02,  7.6950905e-03,\n",
       "        4.1096595e-05,  3.1721466e-03, -1.4527968e-02, -5.9980280e-03,\n",
       "       -6.4899155e-05, -5.6579905e-03,  5.7013305e-03,  3.2243149e-03,\n",
       "       -4.6917303e-03, -9.5418142e-03, -5.4423800e-03,  5.8823973e-03,\n",
       "       -3.0356590e-03,  2.3061300e-03,  3.1461369e-03, -1.2997809e-02,\n",
       "       -1.0747216e-02, -2.2088077e-03, -2.1110619e-03, -3.4852810e-03,\n",
       "        9.3441484e-03, -1.1045738e-03, -6.5120934e-03,  2.1644083e-03,\n",
       "        1.5114731e-02, -4.7778478e-03,  1.7627100e-02,  1.2173986e-02,\n",
       "       -3.4687542e-03,  1.3271155e-02,  4.9006119e-03,  7.0410105e-03,\n",
       "       -3.8161071e-03, -1.0893447e-02, -7.8541357e-03,  5.9661041e-03,\n",
       "        1.7540790e-03, -7.1353428e-03,  8.6165713e-03, -3.2726419e-03,\n",
       "        9.0626897e-03,  4.7419830e-03,  2.9499391e-03, -8.9774569e-03,\n",
       "        2.8899440e-03, -2.4488321e-04,  7.1161059e-03,  4.2709084e-03,\n",
       "        9.2254570e-03,  2.2936056e-03,  6.8108682e-05, -1.5841836e-02,\n",
       "       -5.1282370e-03, -3.1544603e-03,  6.9608595e-03,  7.2273635e-03,\n",
       "       -1.0011917e-02, -1.6093314e-04,  6.8439648e-04,  2.8383173e-03,\n",
       "        1.8429565e-03,  1.0983055e-02,  7.6055471e-03,  1.6203228e-03,\n",
       "        7.7728657e-03, -8.6520647e-04,  1.1396561e-02,  8.9310864e-03,\n",
       "        5.2408734e-03,  6.4755478e-03,  1.7736955e-03,  1.2977807e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv['eau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8692312"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_two_words(model2, 'eau', 'potable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60812277"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_two_words(model2, 'eau', 'coupure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5900843"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_two_words(model2, 'eau', 'tunis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('les', 0.8799888491630554),\n",
       " ('potable', 0.869231104850769),\n",
       " ('leau', 0.8554626107215881),\n",
       " ('plus', 0.8459827303886414),\n",
       " ('sans', 0.8456719517707825),\n",
       " ('a', 0.8417167067527771),\n",
       " ('faut', 0.8225437998771667),\n",
       " ('tunisie', 0.8008747696876526),\n",
       " ('sous', 0.7780416011810303),\n",
       " ('jeunes', 0.7747730016708374)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.most_similar('eau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('les', 0.9797747135162354),\n",
       " ('potable', 0.97902512550354),\n",
       " ('plus', 0.976499617099762),\n",
       " ('faut', 0.96953284740448),\n",
       " ('leau', 0.9686856269836426),\n",
       " ('sensibles', 0.9647523164749146),\n",
       " ('deau', 0.9641631245613098),\n",
       " ('a', 0.9630036354064941),\n",
       " ('fragiles', 0.9612061977386475),\n",
       " ('devient', 0.9610947370529175)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('eau')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pre-trained word embedding\n",
    "\n",
    "We use:\n",
    "- google news --> doesn't cover French words\n",
    "- Godin word2vec for twitter https://fredericgodin.com/software/ \n",
    "--> Not adapted for tweets in French.\n",
    "- fastText for french docs https://fasttext.cc/docs/en/support.html\n",
    "--> Too general... not adapted to twitter or to the topic (water)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 GoogleNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/basho/fadouaproject/SafeWater/model/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model['eau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"tunisie perturbations coupures leau potable cités ettadhamen douar hicher reprise prévue soir selon sonede\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'tunisie' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-6f71e7397506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-129-6f71e7397506>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'tunisie' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "vectors = [model[x] for x in sample.split(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Godin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/basho/fadouaproject/SafeWater/model/word2vec_twitter_model/word2vec_twitter_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(path, binary=True, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access vectors for specific words with a keyed lookup:\n",
    "vector = model['eau']\n",
    "#vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'gouvernorats' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-416c6a6ced26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gouvernorats'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# gouvernorats not included in the vocabulary. Godin word2vec is not for french language\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'gouvernorats' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "vector = model['gouvernorats'] # gouvernorats not included in the vocabulary. Godin word2vec is not for french language\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'coupures' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-14bd6e18d265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-169-14bd6e18d265>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'coupures' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "vectors = [model[x] for x in sample.split(' ')]\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def make_data_from_tweets(tweets):\n",
    "#    filename = 0\n",
    "#    file = open('data.txt','a')\n",
    "#    for tw in tweets:\n",
    "#        file.write(tw)\n",
    "#        file.write('\\n')\n",
    "#    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenames = ['file1.txt', 'file2.txt', ...]\n",
    "#def collect_corpora(corpus, path,size=464):\n",
    "#    with open(path, 'w') as outfile:\n",
    "#        for i in range(1,size+1):\n",
    "#            with open(corpus+str(i)+\".txt\") as infile:\n",
    "#                outfile.write(infile.read())\n",
    "#                outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " #collect_corpora(\"/Users/basho/fadouaproject2/water/corpus/\",\"/Users/basho/fadouaproject2/water/data0807.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3d11137f9122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_data_from_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_collection' is not defined"
     ]
    }
   ],
   "source": [
    "#make_data_from_tweets(clean_collection(tweets, lem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/basho/fadouaproject/SafeWater/model/cc.fr.300.bin'\n",
    "\n",
    "# CBOW model\n",
    "model = fasttext.cbow('data0807.txt', path)\n",
    "\n",
    "# Access vectors for specific words with a keyed lookup:\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model['eau']\n",
    "#vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0026333394926041365,\n",
       " 0.0004583431000355631,\n",
       " 0.0015618990873917937,\n",
       " -0.00040297824307344854,\n",
       " 0.0009339713724330068,\n",
       " -0.0019025299698114395,\n",
       " 0.00014381635992322117,\n",
       " -0.0005928538739681244,\n",
       " -0.0006212163134478033,\n",
       " -0.0003661340451799333,\n",
       " -9.695602784631774e-05,\n",
       " -0.00032445104443468153,\n",
       " 0.00028244106215424836,\n",
       " 0.0006108568049967289,\n",
       " -0.00011309773981338367,\n",
       " 0.0002985682513099164,\n",
       " -0.0001528688590042293,\n",
       " 0.0012167314998805523,\n",
       " 0.0003845634637400508,\n",
       " -0.000994060654193163,\n",
       " 0.0013144734548404813,\n",
       " -0.00022949010599404573,\n",
       " -0.0014799172058701515,\n",
       " 0.002377656754106283,\n",
       " 0.0006480717565864325,\n",
       " 0.00016797886928543448,\n",
       " -0.0015981632750481367,\n",
       " -0.001310986583121121,\n",
       " -0.0005503213033080101,\n",
       " 0.0013695774832740426,\n",
       " 0.0020908555015921593,\n",
       " -0.0001683756709098816,\n",
       " 0.0005655263084918261,\n",
       " -0.0006213497836142778,\n",
       " -0.0023903746623545885,\n",
       " -0.00043916067807003856,\n",
       " -0.00045638278243131936,\n",
       " -0.0009654165478423238,\n",
       " -0.0008394665201194584,\n",
       " -0.0016285899328067899,\n",
       " 0.0017740140901878476,\n",
       " 0.0003375000087544322,\n",
       " -0.0026227880734950304,\n",
       " 0.0009646571706980467,\n",
       " 0.0012303466210141778,\n",
       " 0.0015695336041972041,\n",
       " 0.0025633363984525204,\n",
       " -0.0007329768850468099,\n",
       " 0.0005839735385961831,\n",
       " 0.0007767853094264865,\n",
       " -0.00010849439422599971,\n",
       " -0.0015865667955949903,\n",
       " 0.0010582719696685672,\n",
       " -0.001293010194785893,\n",
       " 0.0015059191500768065,\n",
       " 0.0010309192584827542,\n",
       " -0.0024349994491785765,\n",
       " -0.0018563795601949096,\n",
       " 0.0006680385558865964,\n",
       " 0.0010397650767117739,\n",
       " -0.0006901883170939982,\n",
       " 0.0009385590674355626,\n",
       " 0.0018007636535912752,\n",
       " 0.0003649224527180195,\n",
       " 0.00021111105161253363,\n",
       " -0.001303221913985908,\n",
       " 0.0014865597477182746,\n",
       " 0.0006690075388178229,\n",
       " 0.0006417119293473661,\n",
       " -0.0008398752543143928,\n",
       " 0.00045540404971688986,\n",
       " -0.0023712217807769775,\n",
       " -0.0012273890897631645,\n",
       " 0.00011829703726107255,\n",
       " 0.0015696395421400666,\n",
       " 0.0005880844546481967,\n",
       " 0.003357226261869073,\n",
       " -0.001130265649408102,\n",
       " 0.0015657764161005616,\n",
       " 0.00026536587392911315,\n",
       " 0.0017083333805203438,\n",
       " 0.0009109199745580554,\n",
       " -0.000694864138495177,\n",
       " 0.001541385892778635,\n",
       " -0.001074025291018188,\n",
       " -0.00012027513730572537,\n",
       " 0.0004448466352187097,\n",
       " 0.0006002426380291581,\n",
       " -0.001081716502085328,\n",
       " 0.0009914576075971127,\n",
       " -0.0010154081974178553,\n",
       " 0.0016642700647935271,\n",
       " -2.9875774998799898e-05,\n",
       " -0.0009641371434554458,\n",
       " 0.0007022935315035284,\n",
       " -0.0004631578049156815,\n",
       " -0.0006003174348734319,\n",
       " 0.0015710988081991673,\n",
       " 0.0009804185247048736,\n",
       " -0.00028813950484618545]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model['gouvernorats']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [model[x] for x in [s for s in clean_collection(tweets, lem=True)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.12798798e-03, -9.11411131e-04,  6.00925647e-04, ...,\n",
       "        -2.04028678e-04,  3.56815406e-04,  4.45286023e-05],\n",
       "       [ 1.61809835e-03, -5.67893614e-04,  1.28119544e-03, ...,\n",
       "        -2.38617853e-04,  2.89702060e-04, -4.39771189e-04],\n",
       "       [ 1.08614517e-03, -7.07134022e-04,  1.15271588e-03, ...,\n",
       "        -8.15522508e-04,  1.47608735e-04, -8.02294817e-04],\n",
       "       ...,\n",
       "       [ 1.60457962e-03, -3.60681006e-04,  1.18202635e-03, ...,\n",
       "         6.99559751e-05, -1.19417920e-04, -3.74757510e-04],\n",
       "       [ 9.85771301e-04, -3.65581887e-04,  1.89663740e-04, ...,\n",
       "         2.07624587e-04,  6.85874256e-04,  5.67355368e-04],\n",
       "       [ 1.14639511e-03, -1.08763095e-04, -4.35829934e-05, ...,\n",
       "         7.16942741e-05, -2.29802725e-04,  1.19460536e-04]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix=np.vstack(vectors)\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 100)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8360370641277646"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cosine_similarity('eau','tunis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111906809093568"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cosine_similarity('eau','coupure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806099860839453"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cosine_similarity('eau','projet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866360430159756"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cosine_similarity('eau','distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'19',\n",
       " '2',\n",
       " '2010',\n",
       " '2019',\n",
       " '21h',\n",
       " '24',\n",
       " '28',\n",
       " '35',\n",
       " '4',\n",
       " '55',\n",
       " '63',\n",
       " '70',\n",
       " '</s>',\n",
       " 'a',\n",
       " 'acaweadvocate',\n",
       " 'accès',\n",
       " 'adoucissante',\n",
       " 'ain',\n",
       " 'amina',\n",
       " 'annonce',\n",
       " 'apaisante',\n",
       " 'approvisionnement',\n",
       " 'après',\n",
       " 'ariana',\n",
       " 'assainissement',\n",
       " 'aussi',\n",
       " 'avant',\n",
       " 'bangui',\n",
       " 'beaucoup',\n",
       " 'besoin',\n",
       " 'bien',\n",
       " 'boire',\n",
       " 'bonheur',\n",
       " 'bouteille',\n",
       " 'calmante',\n",
       " 'cameroun',\n",
       " 'canal',\n",
       " 'cause',\n",
       " 'centrafrique',\n",
       " 'cest',\n",
       " 'cette',\n",
       " 'chaque',\n",
       " 'chez',\n",
       " 'comme',\n",
       " 'comment',\n",
       " 'commun',\n",
       " 'compose',\n",
       " 'compte',\n",
       " 'con',\n",
       " 'conduites',\n",
       " 'coupe',\n",
       " 'coupure',\n",
       " 'coupures',\n",
       " 'deau',\n",
       " 'demain',\n",
       " 'depuis',\n",
       " 'deux',\n",
       " 'devient',\n",
       " 'dhydratation',\n",
       " 'dire',\n",
       " 'disponible',\n",
       " 'distribution',\n",
       " 'doit',\n",
       " 'domicile',\n",
       " 'droit',\n",
       " 'dun',\n",
       " 'dune',\n",
       " 'délavage',\n",
       " 'délaver',\n",
       " 'délicates',\n",
       " 'dénombre',\n",
       " 'déshydratation',\n",
       " 'eau',\n",
       " 'eaux',\n",
       " 'el',\n",
       " 'enfants',\n",
       " 'face',\n",
       " 'faire',\n",
       " 'fait',\n",
       " 'fatymdiallo',\n",
       " 'faut',\n",
       " 'fourat',\n",
       " 'fragiles',\n",
       " 'fréquente',\n",
       " 'ftdes',\n",
       " 'gafsa',\n",
       " 'garci',\n",
       " 'gens',\n",
       " 'gouvernement',\n",
       " 'grand',\n",
       " 'grenouille',\n",
       " 'habitants',\n",
       " 'hajerbj',\n",
       " 'heures',\n",
       " 'homme',\n",
       " 'hypotension',\n",
       " 'ils',\n",
       " 'immédiatement',\n",
       " 'intestin',\n",
       " 'jamais',\n",
       " 'jannet',\n",
       " 'jeans',\n",
       " 'jelma',\n",
       " 'jendouba',\n",
       " 'jeunes',\n",
       " 'jour',\n",
       " 'korba',\n",
       " 'lait',\n",
       " 'lapprovisionnement',\n",
       " 'leaderstunisie',\n",
       " 'leau',\n",
       " 'les',\n",
       " 'lextrême',\n",
       " 'litres',\n",
       " 'logiciellibre',\n",
       " 'là',\n",
       " 'magnésium',\n",
       " 'manque',\n",
       " 'mansour',\n",
       " 'mardi',\n",
       " 'marques',\n",
       " 'marwa',\n",
       " 'matin',\n",
       " 'mature',\n",
       " 'mayahach',\n",
       " 'mer',\n",
       " 'mesure',\n",
       " 'met',\n",
       " 'milliards',\n",
       " 'millions',\n",
       " 'minérale',\n",
       " 'minérales',\n",
       " 'monastir',\n",
       " 'mort',\n",
       " 'ni',\n",
       " 'nont',\n",
       " 'nord',\n",
       " 'odilon236',\n",
       " 'oktor',\n",
       " 'opendata',\n",
       " 'orthostatique',\n",
       " 'où',\n",
       " 'parfum',\n",
       " 'partir',\n",
       " 'passer',\n",
       " 'peau',\n",
       " 'peaux',\n",
       " 'pendant',\n",
       " 'personne',\n",
       " 'personnes',\n",
       " 'perturbation',\n",
       " 'perturbations',\n",
       " 'peu',\n",
       " 'peut',\n",
       " 'photos',\n",
       " 'pied',\n",
       " 'plage',\n",
       " 'plus',\n",
       " 'plusieurs',\n",
       " 'population',\n",
       " 'potable',\n",
       " 'prix',\n",
       " 'problème',\n",
       " 'production',\n",
       " 'projet',\n",
       " 'projets',\n",
       " 'propose',\n",
       " 'près',\n",
       " 'pénurie',\n",
       " 'périphéries',\n",
       " 'quand',\n",
       " 'quelques',\n",
       " 'raoued',\n",
       " 'recherche',\n",
       " 'reconnu',\n",
       " 'region',\n",
       " 'reportage',\n",
       " 'reprise',\n",
       " 'rien',\n",
       " 'robinet',\n",
       " 'rouge',\n",
       " 'route',\n",
       " 'rt',\n",
       " 'région',\n",
       " 'régions',\n",
       " 'réparées',\n",
       " 'rééquilibrante',\n",
       " 'sabotées',\n",
       " 'sabrine',\n",
       " 'safia',\n",
       " 'sait',\n",
       " 'salon',\n",
       " 'sans',\n",
       " 'sauvagement',\n",
       " 'selim',\n",
       " 'selon',\n",
       " 'sensibles',\n",
       " 'sfax',\n",
       " 'si',\n",
       " 'sidi',\n",
       " 'sonede',\n",
       " 'sous',\n",
       " 'sœur',\n",
       " 'terrain',\n",
       " 'toujours',\n",
       " 'tourne',\n",
       " 'tous',\n",
       " 'tout',\n",
       " 'toutes',\n",
       " 'traitement',\n",
       " 'travaux',\n",
       " 'travers',\n",
       " 'tunis',\n",
       " 'tunisie',\n",
       " 'tunivisions',\n",
       " 'unités',\n",
       " 'usine',\n",
       " 'vais',\n",
       " 'via',\n",
       " 'vidéo',\n",
       " 'vie',\n",
       " 'village',\n",
       " 'voici',\n",
       " 'vol',\n",
       " 'webdotn',\n",
       " 'wolordé',\n",
       " 'zones',\n",
       " 'ça',\n",
       " 'électricité',\n",
       " 'épineux',\n",
       " 'équipements'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.words #.difference('eau','coupure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/basho/fadouaproject2/water/data0807_labeled.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets = pd.DataFrame(data)\n",
    "train_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data.train.txt', 'w+')\n",
    "for i in train_tweets.index:\n",
    "    if train_tweets[\"target\"][i] == 1.0:\n",
    "        line = '__label__'+str(1)+' '+train_tweets[\"tweet\"][i]+'\\n'\n",
    "        file.write(line)\n",
    "    else:\n",
    "        line = '__label__'+str(0)+' '+train_tweets[\"tweet\"][i]+'\\n'\n",
    "        file.write(line)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = fasttext.supervised('data.train.txt', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict('Coupure deau prevue a Tunis et Ariana le soir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
