{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation in Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_path = open(\"/Users/basho/fadouaproject/SafeWater/files/twData.csv\",\"r\")\n",
    "tw_data = pd.read_csv(tw_path, header=0)\n",
    "tweets = tw_data.TwContent.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CountVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vec(text):\n",
    "    vectorizer = CountVectorizer()\n",
    "    vocabulary=vectorizer.fit(text)\n",
    "    doc_term_matrix= vectorizer.transform(text)\n",
    "    final=doc_term_matrix.toarray()\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec([tweets[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Making corporus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('perturbations', 'perturbation'), ('coupures', 'coupure'), (' ', ' '), ('approvisionnement', 'approvisionnemer'), ('eau', 'eau'), ('potable', 'potable'), ('quelques', 'quelque'), ('régions', 'région'), ('jendouba', 'jendouba'), ('béja', 'béjer')]\n",
      "tweet 1:  les gouvernorats siliana kasserine jendouba souffrent coupures  eau potable\n",
      "tweet 2:  perturbations coupures  approvisionnement eau potable les gouvernorats siliana kasserine jendouba\n",
      "tweet 1:  les gouvernorats siliana kasserine jendouba souffrent coupures  eau potable\n",
      "tweet 2:  vol équipements sonede prive plusieurs régions  eau potable\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.Water_nlp import clean_collection\n",
    "import os\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdir = 'corpus/'\n",
    "if not os.path.isdir(corpusdir):\n",
    "    os.mkdir(corpusdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text(data):\n",
    "    filename = 0\n",
    "    for text in data:\n",
    "        print(text)\n",
    "        filename+=1\n",
    "        file = open(corpusdir+str(filename)+'.txt','w')\n",
    "        file.write(text)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_collection(tweets, lem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcorpus = PlaintextCorpusReader(corpusdir, '.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ariana', 'pertrubation', 'distribution', 'deau', ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cccess the plaintext; outputs pure string/basestring.\n",
    "#newcorpus.raw().strip()\n",
    "\n",
    "# Access paragraphs in the corpus. (list of list of list of strings)\n",
    "# NOTE: NLTK automatically calls nltk.tokenize.sent_tokenize and \n",
    "#       nltk.tokenize.word_tokenize.\n",
    "#\n",
    "# Each element in the outermost list is a paragraph, and\n",
    "# Each paragraph contains sentence(s), and\n",
    "# Each sentence contains token(s)\n",
    "#newcorpus.paras()\n",
    "#newcorpus.paras(newcorpus.fileids()[43])\n",
    "\n",
    "# Access sentences in the corpus. (list of list of strings)\n",
    "# NOTE: That the texts are flattened into sentences that contains tokens.\n",
    "#newcorpus.sents()\n",
    "#newcorpus.sents(newcorpus.fileids()[103])\n",
    "\n",
    "# Access just tokens/words in the corpus. (list of strings)\n",
    "#newcorpus.words()\n",
    "newcorpus.words(newcorpus.fileids()[56])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Word2Vec via gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(newcorpus.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['les',\n",
       " 'jendouba',\n",
       " 'coupures',\n",
       " 'eau',\n",
       " 'potable',\n",
       " 'nord',\n",
       " 'vol',\n",
       " 'équipements',\n",
       " 'sonede',\n",
       " 'plusieurs',\n",
       " 'régions',\n",
       " 'leau',\n",
       " 'travaux',\n",
       " 'rt',\n",
       " 'électricité',\n",
       " 'a',\n",
       " 'bangui',\n",
       " 'odilon236',\n",
       " 'centrafrique',\n",
       " 'gouvernement',\n",
       " 'périphéries',\n",
       " 'faut',\n",
       " 'aussi',\n",
       " 'tunisie',\n",
       " 'prix',\n",
       " 'enfants',\n",
       " 'vie',\n",
       " 'accès',\n",
       " 'assainissement',\n",
       " 'millions',\n",
       " 'personnes',\n",
       " 'sans',\n",
       " 'dun',\n",
       " 'dune',\n",
       " 'avant',\n",
       " 'deau',\n",
       " 'travers',\n",
       " 'milliards',\n",
       " 'cette',\n",
       " 'droit',\n",
       " 'reprise',\n",
       " 'approvisionnement',\n",
       " 'région',\n",
       " 'toujours',\n",
       " 'via',\n",
       " 'selon',\n",
       " 'peau',\n",
       " 'plus',\n",
       " 'besoin',\n",
       " 'dhydratation',\n",
       " 'peaux',\n",
       " 'mature',\n",
       " 'délicates',\n",
       " 'sensibles',\n",
       " 'fragiles',\n",
       " 'voici',\n",
       " 'bonheur',\n",
       " 'rééquilibrante',\n",
       " 'calmante',\n",
       " 'adoucissante',\n",
       " 'apaisante',\n",
       " 'disponible',\n",
       " 'immédiatement',\n",
       " 'intestin',\n",
       " 'ni',\n",
       " 'beaucoup',\n",
       " 'jamais',\n",
       " 'cest',\n",
       " 'sait',\n",
       " 'reconnu',\n",
       " 'nont',\n",
       " 'acaweadvocate',\n",
       " 'reportage',\n",
       " 'mort',\n",
       " '4',\n",
       " 'recherche',\n",
       " 'wolordé',\n",
       " 'lextrême',\n",
       " 'cameroun',\n",
       " 'mesure',\n",
       " 'con',\n",
       " 'bouteille',\n",
       " 'depuis',\n",
       " 'là',\n",
       " 'pénurie',\n",
       " 'eaux',\n",
       " 'parfum',\n",
       " 'bien',\n",
       " 'si',\n",
       " 'deux',\n",
       " 'litres',\n",
       " 'ariana',\n",
       " 'distribution',\n",
       " 'demain',\n",
       " 'partir',\n",
       " '21h',\n",
       " 'boire',\n",
       " 'près',\n",
       " 'el',\n",
       " 'compose',\n",
       " 'grand',\n",
       " 'salon',\n",
       " 'magnésium',\n",
       " 'toutes',\n",
       " 'population',\n",
       " 'terrain',\n",
       " 'homme',\n",
       " 'korba',\n",
       " 'quelques',\n",
       " '2',\n",
       " 'perturbation',\n",
       " 'raoued',\n",
       " 'unités',\n",
       " 'tout',\n",
       " 'peut',\n",
       " 'dire',\n",
       " 'comme',\n",
       " 'selim',\n",
       " 'region',\n",
       " 'monastir',\n",
       " 'ftdes',\n",
       " 'dénombre',\n",
       " '63',\n",
       " 'délavage',\n",
       " '55',\n",
       " 'délaver',\n",
       " 'jeans',\n",
       " '70',\n",
       " 'coupure',\n",
       " 'mardi',\n",
       " '19',\n",
       " '2019',\n",
       " 'tunis',\n",
       " 'jour',\n",
       " 'quand',\n",
       " 'perturbations',\n",
       " 'opendata',\n",
       " 'passer',\n",
       " 'logiciellibre',\n",
       " 'commun',\n",
       " 'robinet',\n",
       " 'face',\n",
       " 'projets',\n",
       " 'projet',\n",
       " '2010',\n",
       " '35',\n",
       " 'canal',\n",
       " 'production',\n",
       " 'traitement',\n",
       " 'tunivisions',\n",
       " 'manque',\n",
       " 'devient',\n",
       " 'problème',\n",
       " 'épineux',\n",
       " 'annonce']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= list(model.wv.vocab)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('potable', 0.6736690998077393),\n",
       " ('mature', 0.6441358327865601),\n",
       " ('leau', 0.6415693759918213),\n",
       " ('rt', 0.597144365310669),\n",
       " ('fragiles', 0.5935059189796448),\n",
       " ('unités', 0.5852980613708496),\n",
       " ('voici', 0.5848841071128845),\n",
       " ('épineux', 0.5736327171325684),\n",
       " ('devient', 0.5702157616615295),\n",
       " ('faut', 0.5639740824699402)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=model.most_similar('eau')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coupure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:876: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "dissimlar_words = model.doesnt_match('coupure eau potable'.split())\n",
    "print(dissimlar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_two_words(w1, w2):\n",
    "    sim = model.similarity(w1,w2)\n",
    "    print(\"The similarity between <{}> and <{}>: \".format(w1, w2), sim)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between <eau> and <potable>:  0.6736691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6736691"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_two_words('eau', 'potable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between <eau> and <coupure>:  0.53463686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.53463686"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_two_words('eau', 'coupure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between <eau> and <jendouba>:  -0.00029225182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.00029225182"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_two_words('eau', 'jendouba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between <eau> and <tunis>:  0.43528774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.43528774"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_two_words('eau', 'tunis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pre-trained word embedding\n",
    "\n",
    "We use:\n",
    "- Godin word2vec for twitter https://fredericgodin.com/software/ \n",
    "--> Not adapted for tweets in French.\n",
    "- fastText for french docs https://fasttext.cc/docs/en/support.html\n",
    "--> Too general... not adapted to twitter or to the topic (water)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Godin model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/basho/fadouaproject/SafeWater/model/word2vec_twitter_model/word2vec_twitter_model.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(path, binary=True, unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access vectors for specific words with a keyed lookup:\n",
    "vector = model['eau']\n",
    "#vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-42977f4d420e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector = model['gouvernorats'] # gouvernorats not included in the vocabulary. Godin word2vec is not for french language\n",
    "#vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 fastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_from_tweets(tweets):\n",
    "    filename = 0\n",
    "    file = open('data.txt','a')\n",
    "    for tw in tweets:\n",
    "        file.write(tw)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3d11137f9122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_data_from_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_collection' is not defined"
     ]
    }
   ],
   "source": [
    "make_data_from_tweets(clean_collection(tweets, lem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/basho/fadouaproject/SafeWater/model/cc.fr.300.bin'\n",
    "\n",
    "# CBOW model\n",
    "model = fasttext.cbow('/Users/basho/fadouaproject/SafeWater/data.txt', path)\n",
    "\n",
    "# Access vectors for specific words with a keyed lookup:\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model['eau']\n",
    "#vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model['gouvernorats']\n",
    "#vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = [model[x] for x in [s for s in clean_collection(tweets, lem=True)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors=np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01510056, -0.04534726, -0.02222504, ..., -0.03518727,\n",
       "         0.15241031,  0.12867574],\n",
       "       [ 0.01911572, -0.06287023, -0.03116055, ..., -0.04759455,\n",
       "         0.20960853,  0.17671601],\n",
       "       [ 0.01325244, -0.04773147, -0.02495549, ..., -0.03608626,\n",
       "         0.16396153,  0.1380997 ],\n",
       "       ...,\n",
       "       [ 0.00328554, -0.00538237, -0.00224848, ..., -0.0023036 ,\n",
       "         0.00906369,  0.00774935],\n",
       "       [ 0.01953404, -0.07345748, -0.03722223, ..., -0.05470436,\n",
       "         0.24624388,  0.20672752],\n",
       "       [ 0.00290398, -0.00419246, -0.00149947, ..., -0.00213428,\n",
       "         0.00539392,  0.00481484]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix=np.vstack(vectors)\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991000063539089"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cosine_similarity('eau','tunis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998339438408912"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cosine_similarity('eau','coupure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994097436713149"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cosine_similarity('eau','projet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996437167357842"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cosine_similarity('eau','distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'108',\n",
       " '12',\n",
       " '15',\n",
       " '19',\n",
       " '2',\n",
       " '20',\n",
       " '2010',\n",
       " '2019',\n",
       " '3',\n",
       " '35',\n",
       " '4',\n",
       " '5',\n",
       " '55',\n",
       " '611',\n",
       " '63',\n",
       " '70',\n",
       " '85rt',\n",
       " 'a',\n",
       " 'absorbe',\n",
       " 'acaweadvocate',\n",
       " 'accès',\n",
       " 'adoucissante',\n",
       " 'analysé',\n",
       " 'annonce',\n",
       " 'années',\n",
       " 'ans',\n",
       " 'antiâge',\n",
       " 'apaisante',\n",
       " 'apprend',\n",
       " 'approvisionnement',\n",
       " 'ariana',\n",
       " 'arrêt',\n",
       " 'assainissement',\n",
       " 'astes',\n",
       " 'augmentation',\n",
       " 'augmente',\n",
       " 'aujourd',\n",
       " 'aussi',\n",
       " 'autant',\n",
       " 'autorités',\n",
       " 'avant',\n",
       " 'baie',\n",
       " 'balbutiante',\n",
       " 'bangui',\n",
       " 'basé',\n",
       " 'beaucoup',\n",
       " 'besoin',\n",
       " 'bien',\n",
       " 'boire',\n",
       " 'bonheur',\n",
       " 'bouteille',\n",
       " 'calmante',\n",
       " 'cameroun',\n",
       " 'canal',\n",
       " 'candidat',\n",
       " 'capacité',\n",
       " 'casa',\n",
       " 'centrafrique',\n",
       " 'cest',\n",
       " 'cette',\n",
       " 'cettert',\n",
       " 'chambres',\n",
       " 'chercheurs',\n",
       " 'choix',\n",
       " 'chronique',\n",
       " 'citoyens',\n",
       " 'comme',\n",
       " 'commun',\n",
       " 'compose',\n",
       " 'conrt',\n",
       " 'consacrés',\n",
       " 'contre',\n",
       " 'coucher',\n",
       " 'coupe',\n",
       " 'coupure',\n",
       " 'coupures',\n",
       " 'crise',\n",
       " 'cuisine',\n",
       " 'deau',\n",
       " 'demain',\n",
       " 'denfants',\n",
       " 'depuis',\n",
       " 'dernières',\n",
       " 'desserte',\n",
       " 'desservant',\n",
       " 'deux',\n",
       " 'devient',\n",
       " 'dhydratation',\n",
       " 'dinars',\n",
       " 'dire',\n",
       " 'disponible',\n",
       " 'distribution',\n",
       " 'donc',\n",
       " 'droit',\n",
       " 'dun',\n",
       " 'dune',\n",
       " 'durant',\n",
       " 'découvert',\n",
       " 'délavage',\n",
       " 'délaver',\n",
       " 'délicates',\n",
       " 'dénombre',\n",
       " 'développement',\n",
       " 'eau',\n",
       " 'eaux',\n",
       " 'el',\n",
       " 'encore',\n",
       " 'enfants',\n",
       " 'entrave',\n",
       " 'environnementale',\n",
       " 'face',\n",
       " 'fait',\n",
       " 'famille',\n",
       " 'faut',\n",
       " 'fautrt',\n",
       " 'femme',\n",
       " 'feu',\n",
       " 'filtrant',\n",
       " 'fondouk',\n",
       " 'fragiles',\n",
       " 'ftdes',\n",
       " 'février',\n",
       " 'gafrej',\n",
       " 'ghedir',\n",
       " 'golla',\n",
       " 'gouvernement',\n",
       " 'gouvernorats',\n",
       " 'grand',\n",
       " 'gros',\n",
       " 'habitants',\n",
       " 'histoire',\n",
       " 'homme',\n",
       " 'hui',\n",
       " 'humains',\n",
       " 'imed',\n",
       " 'importants',\n",
       " 'inaugure',\n",
       " 'intermédiaire',\n",
       " 'intestin',\n",
       " 'jamais',\n",
       " 'jeans',\n",
       " 'jedid',\n",
       " 'jendouba',\n",
       " 'jour',\n",
       " 'korba',\n",
       " 'lait',\n",
       " 'lapprovisionnement',\n",
       " 'leau',\n",
       " 'les',\n",
       " 'lextrême',\n",
       " 'liberté',\n",
       " 'libre',\n",
       " 'lit',\n",
       " 'litres',\n",
       " 'logiciellibre',\n",
       " 'là',\n",
       " 'magnésium',\n",
       " 'majerda',\n",
       " 'manque',\n",
       " 'marcher',\n",
       " 'mardi',\n",
       " 'mature',\n",
       " 'mer',\n",
       " 'mesure',\n",
       " 'mettre',\n",
       " 'mille',\n",
       " 'milliards',\n",
       " 'millions',\n",
       " 'millirt',\n",
       " 'minérale',\n",
       " 'mis',\n",
       " 'monastir',\n",
       " 'mort',\n",
       " 'mètre',\n",
       " 'mètres',\n",
       " 'nabeul',\n",
       " 'national',\n",
       " 'nationale',\n",
       " 'ni',\n",
       " 'niveau',\n",
       " 'nont',\n",
       " 'nord',\n",
       " 'norme',\n",
       " 'nuit',\n",
       " 'odilon236',\n",
       " 'oeufs',\n",
       " 'opendata',\n",
       " 'oxygène',\n",
       " 'où',\n",
       " 'parfum',\n",
       " 'partir',\n",
       " 'passer',\n",
       " 'pays',\n",
       " 'peau',\n",
       " 'peaux',\n",
       " 'pendant',\n",
       " 'personne',\n",
       " 'personnes',\n",
       " 'perturbation',\n",
       " 'perturbations',\n",
       " 'peuple',\n",
       " 'peut',\n",
       " 'pied',\n",
       " 'plage',\n",
       " 'plus',\n",
       " 'plusieurs',\n",
       " 'pompe',\n",
       " 'population',\n",
       " 'potable',\n",
       " 'potablechef',\n",
       " 'prive',\n",
       " 'prix',\n",
       " 'problème',\n",
       " 'production',\n",
       " 'projet',\n",
       " 'projets',\n",
       " 'propose',\n",
       " 'près',\n",
       " 'prêt',\n",
       " 'pénurie',\n",
       " 'périphéries',\n",
       " 'quand',\n",
       " 'quelques',\n",
       " 'question',\n",
       " 'raoudha',\n",
       " 'raoued',\n",
       " 'recherche',\n",
       " 'reconnu',\n",
       " 'region',\n",
       " 'reportage',\n",
       " 'reprise',\n",
       " 'robinet',\n",
       " 'routes',\n",
       " 'rt',\n",
       " 'région',\n",
       " 'régions',\n",
       " 'rééquilibrante',\n",
       " 'salle',\n",
       " 'salon',\n",
       " 'sans',\n",
       " 'santé',\n",
       " 'secteur',\n",
       " 'selim',\n",
       " 'selon',\n",
       " 'sensibles',\n",
       " 'seulement',\n",
       " 'si',\n",
       " 'sitin',\n",
       " 'situation',\n",
       " 'sonede',\n",
       " 'sous',\n",
       " 'sérum',\n",
       " 'terrain',\n",
       " 'toujours',\n",
       " 'touristique',\n",
       " 'tous',\n",
       " 'tout',\n",
       " 'toutes',\n",
       " 'traitement',\n",
       " 'transforme',\n",
       " 'transit',\n",
       " 'travaux',\n",
       " 'travers',\n",
       " 'tripoli',\n",
       " 'très',\n",
       " 'tunis',\n",
       " 'tunisie',\n",
       " 'tunivisions',\n",
       " 'unités',\n",
       " 'usine',\n",
       " 'usées',\n",
       " 'veut',\n",
       " 'via',\n",
       " 'vie',\n",
       " 'vivent',\n",
       " 'voici',\n",
       " 'vol',\n",
       " 'wolordé',\n",
       " 'zone',\n",
       " 'zones',\n",
       " 'égalité',\n",
       " 'électricité',\n",
       " 'énergie',\n",
       " 'épineux',\n",
       " 'équipements',\n",
       " 'équipée'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.words #.difference('eau','coupure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fasttext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e025eedf43f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/basho/fadouaproject/SafeWater/data.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fasttext' is not defined"
     ]
    }
   ],
   "source": [
    "classifier = fasttext.supervised('/Users/basho/fadouaproject/SafeWater/data.txt', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.test('Coupure deau prevue a Tunis et Ariana le soir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
